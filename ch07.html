<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" lang="en">
  <head>
    <meta charset="utf-8"/>
    <title>think stats</title>
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"> </script>
    <link rel="stylesheet" type="text/css" href="theme/html/html.css"/>
  </head>
  <body data-type="book">
    <section data-type="chapter" id="estimation" data-pdf-bookmark="Chapter 7. Estimation">
<h1>Estimation</h1>







<section data-type="sect1" id="a0000000212" data-pdf-bookmark="The Estimation Game">
<h1>The Estimation Game</h1>

<p>Let’s play a game. I’ll think of a distribution, and you have to guess what it is. We’ll start out easy and work our way up.</p>

<p><em>I’m thinking of a distribution.</em> I’ll give you two hints; it’s a normal distribution, and here’s a random sample drawn from it:</p>

<p>{−0.441, 1.774, −0.101, −1.138, 2.975, −2.138}</p>

<p>What do you think is the mean parameter, <em>μ</em>, of this distribution?</p>

<p>One choice is to use the sample mean to estimate <em>μ</em>. Up until now, we have used the symbol <em>μ</em> for both the sample mean and the mean parameter, but now to distinguish them I will use x̄ for the sample mean. In this example, x̄ is 0.155, so it would be reasonable to guess <em>μ</em> = 0.155.</p>

<p>This process is called <em>estimation</em>, and the statistic we used (the sample mean) is called an <em>estimator</em>.</p>

<p>Using the sample mean to estimate <em>μ</em> is so obvious that it is hard to imagine a reasonable alternative. But suppose we change the game by introducing outliers.</p>

<p><em>I’m thinking of a distribution.</em> It’s a normal distribution, and here’s a sample that was collected by an unreliable surveyor who occasionally puts the decimal point in the wrong place.</p>

<p>{−0.441, 1.774, −0.101, −1.138, 2.975, −213.8}</p>

<p>Now what’s your estimate of <em>μ</em>? If you use the sample mean, your guess is −35.12. Is that the best choice? What are the alternatives?</p>

<p>One option is to identify and discard outliers, then compute the sample mean of the rest. Another option is to use the median as an estimator.</p>

<p>Which estimator is the best depends on the circumstances (for example, whether there are outliers) and on what the goal is. Are you trying to minimize errors, or maximize your chance of getting the right answer?</p>

<p>If there are no outliers, the sample mean minimizes the <em>mean squared error</em>, or <em>MSE</em>. If we play the game many times, and each time compute the error x̄ − <em>μ</em>, the sample mean minimizes</p>

<p>Where <em>m</em> is the number of times you play the estimation game (not to be confused with <em>n</em>, which is the size of the sample used to compute x̄).</p>

<p>Minimizing MSE is a nice property, but it’s not always the best strategy. For example, suppose we are estimating the distribution of wind speeds at a building site. If we guess too high, we might overbuild the structure, increasing its cost. But if we guess too low, the building might collapse. Because cost as a function of error is asymmetric, minimizing MSE is not the best strategy.</p>

<p>As another example, suppose I roll three six-sided dice and ask you to predict the total. If you get it exactly right, you get a prize; otherwise, you get nothing. In this case, the value that minimizes MSE is 10.5, but that would be a terrible guess. For this game, you want an estimator that has the highest chance of being right, which is a <em>maximum likelihood estimator</em>, or <em>MLE</em>. If you pick 10 or 11, your chance of winning is 1 in 8, and that’s the best you can do.</p>

<p>.</p>
<div data-type="example">
<h5/>

<p>=== Guess the Variance</p>

<p><em>I’m thinking of a distribution.</em> It’s a normal distribution, and here’s a (familiar) sample:</p>

<p>{−0.441, 1.774, −0.101, −1.138, 2.975, −2.138}</p>

<p>What do you think is the variance, <em>σ<em>2</em>, of my distribution? Again, the obvious choice is to use the sample variance as an estimator. I will use <img src="figs/web/equations/img-0048.png" alt="img-0048"/> to denote the sample variance, to distinguish from the unknown parameter <em>σ</em>2</em>.</p>

<p>For large samples, <img src="figs/web/equations/img-0048.png" alt="img-0048"/> is an adequate estimator, but for small samples it tends to be too low. Because of this unfortunate property, it is called a <em>biased</em> estimator.</p>

<p>An estimator is <em>unbiased</em> if the expected total (or mean) error, after many iterations of the estimation game, is 0. Fortunately, there is another simple statistic that is an unbiased estimator of <em>σ__2</em>:</p>

<p>The biggest problem with this estimator is that its name and symbol are used inconsistently. The name “sample variance” can refer to either <img src="figs/web/equations/img-0048.png" alt="img-0048"/> or <img src="figs/web/equations/img-0051.png" alt="img-0051"/> and the symbol <img src="figs/web/equations/img-0048.png" alt="img-0048"/> is used for either or both.</p>

<p>For an explanation of why <img src="figs/web/equations/img-0048.png" alt="img-0048"/> is biased, and a proof that <img src="figs/web/equations/img-0051.png" alt="img-0051"/> is unbiased, see <a href="http://wikipedia.org/wiki/Bias_of_an_estimator">http://wikipedia.org/wiki/Bias_of_an_estimator</a>.</p>

<p>.</p></div>
</section>













<section data-type="sect1" id="a0000000219" data-pdf-bookmark="Understanding Errors">
<h1>Understanding Errors</h1>

<p>Before we go on, let’s clear up a common source of confusion. Properties like MSE and bias are long-term expectations based on many iterations of the estimation game.</p>

<p>While you are playing the game, you don’t know the errors. That is, if I give you a sample and ask you to estimate a parameter, you can compute the value of the estimator, but you can’t compute the error. If you could, you wouldn’t need the estimator!</p>

<p>The reason we talk about estimation error is to describe the behavior of different estimators in the long run. In this chapter we run experiments to examine those behaviors; these experiments are artificial in the sense that we know the actual values of the parameters, so we can compute errors. But when you work with real data, you don’t, so you can’t.</p>

<p>Now let’s get back to the game.</p>
</section>













<section data-type="sect1" id="a0000000220" data-pdf-bookmark="Exponential Distributions">
<h1>Exponential Distributions</h1>

<p><em>I’m thinking of a distribution.</em> It’s an exponential distribution, and here’s a sample:</p>

<p>{5.384, 4.493, 19.198, 2.790, 6.122, 12.844}</p>

<p>What do you think is the parameter, <em>λ</em>, of this distribution?</p>

<p>In general, the mean of an exponential distribution is 1/<em>λ</em>, so working backwards, we might choose</p>

<p><img src="figs/web/equations/img-0052.png" alt="img-0052"/>= 1 / x̄</p>

<p>It is common to use hat notation for estimators, so <img src="figs/web/equations/img-0052.png" alt="img-0052"/> is an estimator of <em>λ</em>. And not just any estimator; it is also the MLE estimator.<a data-type="noteref" id="idp1673680-marker" href="ch07.html#idp1673680"><sup>15</sup></a> So if you want to maximize your chance of guessing <em>λ</em> exactly, <img src="figs/web/equations/img-0052.png" alt="img-0052"/> is the way to go.</p>

<p>But we know that x̄ is not robust in the presence of outliers, so we expect <img src="figs/web/equations/img-0052.png" alt="img-0052"/> to have the same problem.</p>

<p>Maybe we can find an alternative based on the sample median. Remember that the median of an exponential distribution is log(2) / <em>λ</em>, so working backwards again, we can define an estimator</p>

<p>where <em>μ__1/2</em> is the sample median.</p>

<p>.</p>
<div data-type="example">
<h5/>

<p>=== Confidence Intervals</p>

<p>So far, we have looked at estimators that generate single values, known as <em>point estimates</em>. For many problems, we might prefer an interval that specifies an upper and lower bound on the unknown parameter.</p>

<p>Or, more generally, we might want that whole distribution; that is, the range of values the parameter could have, and for each value in the range, a notion of how likely it is.</p>

<p>Let’s start with <em>confidence intervals</em>.</p>

<p><em>I’m thinking of a distribution.</em> It’s an exponential distribution, and here’s a sample:</p>

<p>{5.384, 4.493, 19.198, 2.790, 6.122, 12.844}</p>

<p>I want you to give me a range of values that you think is likely to contain the unknown parameter <em>λ</em>. More specifically, I want a 90% confidence interval, which means that if we play this game over and over, your interval will contain <em>λ</em> 90% of the time.</p>

<p>It turns out that this version of the game is hard, so I’m going to tell you the answer, and all you have to do is test it.</p>

<p>Confidence intervals are usually described in terms of the miss rate, <em>α</em>, so a 90% confidence interval has miss rate <em>α</em> = 0.1. The confidence interval for the <em>λ</em> parameter of an exponential distribution is</p>

<p>where <em>n</em> is the sample size, <img src="figs/web/equations/img-0052.png" alt="img-0052"/> is the mean-based estimator from the previous section, and <em>χ__2</em>(<em>k</em>, <em>x</em>) is the CDF of a chi-squared distribution with <em>k</em> degrees of freedom, evaluated at <em>x</em> (see <a href="http://wikipedia.org/wiki/Chi-square_distribution">http://wikipedia.org/wiki/Chi-square_distribution</a>).</p>

<p>In general, confidence intervals are hard to compute analytically, but relatively easy to estimate using simulation. But first we need to talk about Bayesian estimation.</p>

<p>=== Bayesian Estimation</p>

<p>If you collect a sample and compute a 90% confidence interval, it is tempting to say that the true value of the parameter has a 90% chance of falling in the interval. But from a frequentist point of view, that is not correct because the parameter is an unknown but fixed value. It is either in the interval you computed or not, so the frequentist definition of probability doesn’t apply.</p>

<p>So let’s try a different version of the game.</p>

<p><em>I’m thinking of a distribution.</em> It’s an exponential distribution, and I chose <em>λ</em> from a uniform distribution between 0.5 and 1.5. Here’s a sample, which I’ll call <em>X</em>:</p>

<p>{2.675, 0.198, 1.152, 0.787, 2.717, 4.269}</p>

<p>Based on this sample, what value of <em>λ</em> do you think I chose?</p>

<p>In this version of the game, <em>λ</em> <em>is</em> a random quantity, so we can reasonably talk about its distribution, and we can compute it easily using Bayes’s theorem.</p>

<p>Here are the steps:</p>
<ol>
<li>
<p>Divide the range (0.5, 1.5) into a set of equal-sized bins. For each bin, we define <em>H</em> <em>i</em>, which is the hypothesis that the actual value of <em>λ</em> falls in the <em>i</em> th bin. Since <em>λ</em> was drawn from a uniform distribution, the prior probability, <em>P</em>(<em>H</em> <em>i</em>), is the same for all <em>i</em>.</p>
</li>
<li>
<p>For each hypothesis, we compute the likelihood, <em>P</em>(<em>X</em>|<em>H</em> <em>i</em>), which is the chance of drawing the sample <em>X</em> given <em>H</em> <em>i</em>.</p>
</li>

</ol>

<p>where expo(<em>λ</em>, <em>x</em>) is a function that computes the PDF of the exponential distribution with parameter <em>λ</em>, evaluated at <em>x</em>.</p>

<p>The symbol <img src="figs/web/equations/img-0058.png" alt="img-0058"/> represents the product of a sequence (see <a href="http://wikipedia.org/wiki/Multiplication#Capital_Pi_notation">http://wikipedia.org/wiki/Multiplication#Capital_Pi_notation</a>).</p>
<ol>
<li>
<p>Then by Bayes’s theorem the posterior distribution is</p>
</li>

</ol>

<p><em>P</em>(<em>H</em> <em>i</em>|<em>X</em>)
=
<em>P</em>(<em>H</em> <em>i</em>)
<em>P</em>(<em>X</em>|<em>H</em> <em>i</em>)
/<em>f</em></p>

<p>where <em>f</em> is the normalization factor</p>

<p>Given a posterior distribution, it is easy to compute a confidence interval. For example, to compute a 90% CI, you can use the 5th and 95th percentiles of the posterior.</p>

<p>Bayesian confidence intervals are sometimes called <em>credible intervals</em>; for a discussion of the differences, see <a href="http://wikipedia.org/wiki/Credible_interval">http://wikipedia.org/wiki/Credible_interval</a>.</p>

<p>=== Implementing Bayesian Estimation</p>

<p>To represent the prior distribution, we could use a Pmf, Cdf, or any other representation of a distribution, but since we want to map from a hypothesis to a probability, a Pmf is a natural choice.</p>

<p>Each value in the Pmf represents a hypothesis; for example, the value 0.5 represents the hypothesis that <em>λ</em> is 0.5. In the prior distribution, all hypotheses have the same probability. So we can construct the prior like this:</p>


<pre data-type="programlisting">def MakeUniformSuite(low, high, steps):
    hypos = [low + (high-low) * i / (steps-1.0) for i in range(steps)]
    pmf = Pmf.MakePmfFromList(hypos)
    return pmf</pre>


<p>This function makes and returns a Pmf that represents a collection of related hypotheses, called a <em>suite</em>. Each hypothesis has the same probability, so the distribution is <em>uniform</em>.</p>

<p>The arguments <code>low</code> and <code>high</code> specify the range of values; <code>steps</code> is the number of hypotheses.</p>

<p>To perform the update, we take a suite of hypotheses and a body of evidence:</p>


<pre data-type="programlisting">def Update(suite, evidence):
    for hypo in suite.Values():
        likelihood = Likelihood(evidence, hypo)
        suite.Mult(hypo, likelihood)
    suite.Normalize()</pre>


<p>For each hypothesis in the suite, we multiply the prior probability by the likelihood of the evidence. Then we normalize the suite.</p>

<p>In this function, <code>suite</code> has to be a Pmf, but <code>evidence</code> can be any type, as long as <code>Likelihood</code> knows how to interpret it.</p>

<p>Here’s the likelihood function:</p>


<pre data-type="programlisting">def Likelihood(evidence, hypo):
    param = hypo
    likelihood = 1
    for x in evidence:
        likelihood *= ExpoPdf(x, param)

    return likelihood</pre>


<p>In <code>Likelihood</code>, we assume that <code>evidence</code> is a sample from an exponential distribution and compute the product in the previous section.</p>

<p><code>ExpoPdf</code> evaluates the PDF of the exponential distribution at <code>x</code>:</p>


<pre data-type="programlisting">def ExpoPdf(x, param):
    p = param * math.exp(-param * x)
    return p</pre>


<p>Putting it all together, here’s the code that creates the prior and computes the posterior:</p>


<pre data-type="programlisting">evidence = [2.675, 0.198, 1.152, 0.787, 2.717, 4.269]
prior = MakeUniformSuite(0.5, 1.5, 100)
posterior = prior.Copy()
Update(posterior, evidence)</pre>


<p>You can download the code in this section from <a href="http://thinkstats.com/estimate.py">http://thinkstats.com/estimate.py</a>.</p>

<p>When I think of Bayesian estimation, I imagine a room full of people, where each person has a different guess about whatever you are trying to estimate. So in this example they each have a guess about the correct value of <em>λ</em>.</p>

<p>Initially, each person has a degree of confidence about their own hypothesis. After seeing the evidence, each person updates their confidence based on <em>P</em>(<em>E</em>|<em>H</em>), the likelihood of the evidence, given their hypothesis.</p>

<p>Most often, the likelihood function computes a probability, which is at most 1, so initially everyone’s confidence goes down (or stays the same). But then we normalize, which increases everyone’s confidence.</p>

<p>So the net effect is that some people get more confident, and some less, depending on the relative likelihood of their hypothesis.</p>

<p>=== Censored Data</p>

<p>The following problem appears in Chapter 3 of David MacKay’s <em>Information Theory, Inference and Learning Algorithms</em>, which you can download from <a href="http://www.inference.phy.cam.ac.uk/mackay/itprnn/ps/">http://www.inference.phy.cam.ac.uk/mackay/itprnn/ps/</a>.</p>

<p>Unstable particles are emitted from a source and decay at a distance <em>x</em>, a real number that has an exponential probability distribution with [parameter] <em>λ</em>. Decay events can only be observed if they occur in a window extending from <em>x</em> = 1 cm to <em>x</em> = 20 cm. <em>n</em> decays are observed at locations { <em>x__1</em>, … , <em>x</em> <em>N</em> }. What is <em>λ</em>?</p>

<p>This is an example of an estimation problem with <em>censored data</em>; that is, we know that some data is systematically excluded.</p>

<p>One of the strengths of Bayesian estimation is that it can deal with censored data with relative ease. We can use the method from the previous section with only one change: we have to replace PDF_expo_ with the conditional distribution:</p>

<p>for 1 &lt; <em>x</em> &lt; 20, and 0 otherwise, with</p>

<p>You might remember Z(<em>λ</em>) from <a data-type="xref" href="#expo_pdf">???</a>. I told you to keep it handy.</p>

<p>.</p></div>

<p>.</p>
<div data-type="example">
<h5/>

<p>=== The Locomotive Problem</p>

<p>The locomotive problem is a classic estimation problem also known as the “German tank problem.” Here is the version that appears in Mosteller, <em>Fifty Challenging Problems in Probability</em>:</p>

<p>A railroad numbers its locomotives in order 1..N. One day you see a locomotive with the number 60. Estimate how many locomotives the railroad has.</p>

<p>Before you read the rest of this section, try to answer these questions:</p>
<ol>
<li>
<p>For a given estimate, <img src="figs/web/equations/img-0062.png" alt="img-0062"/>, what is the likelihood of the evidence, <em>P</em>(<em>E</em>|<img src="figs/web/equations/img-0062.png" alt="img-0062"/>)? What is the maximum likelihood estimator?</p>
</li>
<li>
<p>If we see train <em>i</em> it seems reasonable that we would guess some multiple of <em>i</em> so let’s assume <img src="figs/web/equations/img-0062.png" alt="img-0062"/> = <em>a</em> <em>i</em>. What value of <em>a</em> minimizes mean squared error?</p>
</li>
<li>
<p>Still assuming that <img src="figs/web/equations/img-0062.png" alt="img-0062"/> = <em>a</em> <em>i</em> can you find a value of <em>a</em> that makes <img src="figs/web/equations/img-0062.png" alt="img-0062"/> an unbiased estimator?</p>
</li>
<li>
<p>For what value of N is 60 the average value?</p>
</li>
<li>
<p>What is the Bayesian posterior distribution assuming a prior distribution that is uniform from 1 to 200?</p>
</li>

</ol>

<p>For best results, you should take some time to work on these questions before you continue.</p>

<p>For a given estimate, <img src="figs/web/equations/img-0062.png" alt="img-0062"/>, the likelihood of seeing train <em>i</em> is 1/<img src="figs/web/equations/img-0062.png" alt="img-0062"/> if <em>i</em> ≤ <img src="figs/web/equations/img-0062.png" alt="img-0062"/>, and 0 otherwise. So the MLE is <img src="figs/web/equations/img-0062.png" alt="img-0062"/> = <em>i</em>. In other words, if you see train 60 and you want to maximize your chance of getting the answer exactly right, you should guess that there are 60 trains.</p>

<p>But this estimator doesn’t do very well in terms of MSE. We can do better by choosing <img src="figs/web/equations/img-0062.png" alt="img-0062"/> = <em>a</em> <em>i</em>; all we have to do is find a good value for <em>a</em>.</p>

<p>Suppose that there are, in fact, <em>N</em> trains. Each time we play the estimation game, we see train <em>i</em> and guess <em>a</em> <em>i</em>, so the squared error is (<em>a</em> <em>i</em> − <em>N</em>)<em>2</em>.</p>

<p>If we play the game <em>N</em> times and see each train once, the mean squared error is</p>

<p>To minimize MSE, we take the derivative with respect to <em>a</em>:</p>

<p>And solve for <em>a</em>.</p>

<p>At first glance, that doesn’t seem very useful, because <em>N</em> appears on the right-hand side, which suggests that we need to know <em>N</em> to choose <em>a</em>, but if we knew <em>N</em>, we wouldn’t need an estimator in the first place.</p>

<p>However, for large values of <em>N</em>, the optimal value for <em>a</em> converges to 3/2, so we could choose <img src="figs/web/equations/img-0062.png" alt="img-0062"/> = 3_i_/ 2.</p>

<p>To find an unbiased estimator, we can compute the mean error (ME):</p>

<p>And find the value of <em>a</em> that yields ME = 0, which turns out to be</p>

<p>For large values of <em>N</em>, <em>a</em> converges to 2, so we could choose <img src="figs/web/equations/img-0062.png" alt="img-0062"/> = 2_i_.</p>

<p>So far, we have generated three estimators, <em>i</em>, 3_i_/2, and 2_i_, that have the properties of maximizing likelihood, minimizing squared error, and being unbiased.</p>

<p>Yet another way to generate an estimator is to choose the value that makes the population mean equal the sample mean. If we see train <em>i</em>, the sample mean is just <em>i</em>; the train population that has the same mean is <img src="figs/web/equations/img-0062.png" alt="img-0062"/> = 2_i_ − 1.</p>

<p>Finally, to compute the Bayesian posterior distribution, we compute</p>

<p>Where <em>H</em> <em>n</em> is the hypothesis that there are <em>n</em> trains, and <em>i</em> is the evidence: we saw train <em>i</em>. Again, <em>P</em>(<em>i</em>|<em>H</em> <em>n</em>) is 1/<em>n</em> if <em>i</em> &lt; <em>n</em>, and 0 otherwise. The normalizing constant, <em>P</em>(<em>i</em>), is just the sum of the numerators for each hypothesis.</p>

<p>If the prior distribution is uniform from 1 to 200, we start with 200 hypotheses and compute the likelihood for each. You can download an implementation from <a href="http://thinkstats.com/locomotive.py">http://thinkstats.com/locomotive.py</a>. <a data-type="xref" href="#locomotive">Figure 7-1</a> shows what the result looks like.</p>

<figure id="locomotive">
<img src="figs/web/thst_0801.png" alt="thst 0801"/>
<figcaption>Posterior distribution of the number of trains</figcaption>
</figure>

<p>The 90% credible interval for this posterior is [63, 189], which is still quite wide. Seeing one train doesn’t provide strong evidence for any of the hypotheses (although it does rule out the hypotheses with <em>n</em> &lt; <em>i</em>).</p>

<p>If we start with a different prior, the posterior is significantly different, which helps to explain why the other estimators are so diverse.</p>

<p>One way to think of different estimators is that they are implicitly based on different priors. If there is enough evidence to swamp the priors, then all estimators tend to converge; otherwise, as in this case, there is no single estimator that has all of the properties we might want.</p>

<p>.</p></div>
</section>













<section data-type="sect1" id="a0000000244" data-pdf-bookmark="Glossary">
<h1>Glossary</h1>
<dl>
<dt>bias</dt>
<dd>
<p>The tendency of an estimator to be above or below the actual value of the parameter, when averaged over repeated samples.</p>
</dd>
<dt>censored data</dt>
<dd>
<p>A dataset sampled in a way that systematically excludes some data.</p>
</dd>
<dt>confidence interval</dt>
<dd>
<p>An estimate expressed as an interval with a given probability of containing the true value of the parameter.</p>
</dd>
<dt>credible interval</dt>
<dd>
<p>Another name for a Bayesian confidence interval.</p>
</dd>
<dt>estimation</dt>
<dd>
<p>The process of inferring the parameters of a distribution from a sample.</p>
</dd>
<dt>estimator</dt>
<dd>
<p>A statistic used to estimate a parameter.</p>
</dd>
<dt>maximum likelihood estimator</dt>
<dd>
<p>An estimator that computes the point estimate with the highest likelihood.</p>
</dd>
<dt>mean squared error</dt>
<dd>
<p>A measure of estimation error.</p>
</dd>
<dt>point estimate</dt>
<dd>
<p>An estimate expressed as a single value.</p>
</dd>
</dl>
</section>







<aside data-type="footnotes"><p data-type="footnote" id="idp1673680"><a href="ch07.html#idp1673680-marker"><sup>15</sup></a> See <a href="http://wikipedia.org/wiki/Exponential_distribution#Maximum_likelihood">http://wikipedia.org/wiki/Exponential_distribution#Maximum_likelihood</a>.</p></aside></section>
  </body>
</html>
